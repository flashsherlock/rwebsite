---
title: Below-chance accuracy in MVPA
author: Fei
date: '2021-09-27'
categories:
  - reading
tags:
  - MVPA
  - fMRI
slug: below-chance-accuracy-in-mvpa
weight: 1
draft: no
output:
  blogdown::html_page:
    toc: yes
    toc_depth: 2
    number_sections: yes
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>Sometimes, the decoding accuracy of MVPA may lower than chance level, which is confusing. I have found several reasons that may lead to below-chance accuracy in decoding analysis.</p>
<ul>
<li>special data structure (bias)</li>
<li>model parameters (linear vs. non linear)</li>
<li>cross validation methods (leave-one-out vs. k-fold)</li>
<li>sample size (small vs. large)</li>
</ul>
<p>In short, below-chance accuracy is likely caused by data structure and decoding methods, which <a href="http://mvpa.blogspot.com/2013/04/below-chance-classification-accuracy.html">can not be simply interpreted as anti-learning</a>.</p>
<p>For <a href="https://stats.stackexchange.com/questions/220582/svm-always-gives-me-in-average-below-chances-cross-validation-accuracy-with-ra">example</a>, when training with totally random data, the decoding accuracy should fluctuate at the chance level (50%), but actually it may lower than 50%.</p>
<pre class="r"><code>library(&quot;ggplot2&quot;)
library(&quot;dplyr&quot;)
library(&quot;e1071&quot;)
# --------training function ---------
f_train &lt;- function(n, nv = 2,
                    r=F, c=n) {
  # nv: number of features
  # n: number of observations
  set.seed(1)
  # generate random data
  rNum &lt;- rnorm(nv * n)
  rNum &lt;- matrix(rNum, n, nv)
  d &lt;- as.data.frame(rNum)
  
  # generate random labels
  n2 &lt;- n / 2
  labels &lt;- c(array(1, n2),
              array(2, n2))
  if (r) {
  labels &lt;- sample.int(2,n,replace=T)}
  else {
  labels &lt;-  sample(labels)}
  d$condition &lt;- factor(labels)

  # training
  m_trained &lt;- svm(condition ~ .,
    data = d,
    cross = c,
    # cross = nrow(d), # leave one out
    kernel = &quot;linear&quot;,
    cost = 1
  )
  # get CV
  acc &lt;- m_trained$tot.accuracy
}</code></pre>
<pre class="r"><code># no replacement, leave one out
p &lt;- expand.grid(iTest = 1:200, 
                 n = seq(10, 210, 50))
data_test &lt;- p %&gt;%
  group_by(iTest, n) %&gt;%
  do(data.frame(acc = f_train(.$n)))</code></pre>
<p><img src="/post/2021-09-27-below-chance-accuracy-in-mvpa_files/figure-html/plot_data-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>As the sample size increases, variability decreases, and the mean accuracy tends to be 50%. However, there is a persistent small down bias on average, which can be eliminated using sampling with replacement.</p>
<pre class="r"><code># with replacement, leave one out
data_test &lt;- p %&gt;%
  group_by(iTest, n) %&gt;%
  do(data.frame(acc = f_train(.$n,
                              r = T)))</code></pre>
<p><img src="/post/2021-09-27-below-chance-accuracy-in-mvpa_files/figure-html/unnamed-chunk-5-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>In addition, change to 10-fold cross validation may also decrease the variability.</p>
<pre class="r"><code># with replacement, 10-fold cross validation
data_test &lt;- p %&gt;%
  group_by(iTest, n) %&gt;%
  do(data.frame(acc = f_train(.$n,
                              r = F, c=10)))</code></pre>
<p><img src="/post/2021-09-27-below-chance-accuracy-in-mvpa_files/figure-html/unnamed-chunk-7-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Some references:</p>
<ol style="list-style-type: decimal">
<li><a href="https://doi.org/10.1016/j.neuroimage.2017.12.083">The same analysis approach: Practical protection against the pitfalls of novel neuroimaging analysis methods</a></li>
<li><a href="https://doi.org/10.1016/j.neuroimage.2018.09.074">How to control for confounds in decoding analyses of neuroimaging data</a></li>
<li><a href="https://doi.org/10.1002/hbm.23140">Classification Based Hypothesis Testing in Neuroscience: Below-Chance Level Classification Rates and Overlooked Statistical Properties of Linear Parametric Classifiers</a></li>
<li><a href="https://doi.org/10.1371/journal.pcbi.1006486">Multivariate classification of neuroimaging data with nested subclasses: Biased accuracy and implications for hypothesis testing</a></li>
<li><a href="http://dx.doi.org/10.1016/j.neuroimage.2017.08.005">Deconstructing multivariate decoding for the study of brain function</a></li>
</ol>
